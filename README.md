# MNIST-Classification-with-Numpy-and-Backpropagation
Classifying MNIST digits without abstractifying the mathematical optimization involved in deep learning, diving into the meat of backpropagation.

![mnist](http://theanets.readthedocs.io/en/stable/_images/mnist-digits-small.png)

## Mathematical Optimization
Machine Learning uses mathematical optimization to minimize a loss, or measure of how bad the model is, where we then can descend the gradients of the parameters with respect to the loss function, called gradient descent. Finding the partial derivative, or rate of change, of a function with respect to its parameters is finding the gradient of those parameters.
